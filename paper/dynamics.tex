\documentclass{sig-alternate}
\usepackage{graphicx}

\begin{document}
%
% --\item Author Metadata here ---
\conferenceinfo{WWW}{'15}
%\CopyrightYear{2007} % Allows default copyright year (20XX) to be over-ridden \item IF NEED BE.
%\crdata{0-12345-67-8/90/01}  % Allows default copyright data (0-89791-88-6/97/05) to be over-ridden \item IF NEED BE.
% --\item End of Author Metadata ---

\title{The Evolution of Micro-task Crowdsourcing}
\subtitle{The Case of Amazon Mechanical Turk}
% \title{The Dynamics of Micro-task Crowdsourcing -- The Case of MTurk}
% anatomy of a Micro-task Crowdsourcing platform
% unravelling micro-task crowdsourcing dynamics/processes
% the evolution of micro-task crowdsourcing


%\numberofauthors{1}
\author{}

\maketitle
\begin{abstract}

Micro-task crowdsourcing is gaining popularity among serval organizations and research corps to leverage Human Computation in their daily operations. Unlike any other ``technology'', a crowdsourcing platform is subject to many factors that affect the performance, both in terms of speed and quality, of its services. Indeed, such factors shape the \emph{dynamics} of the market. For example, a common result is that increasing the price of a HIT would lead to faster results, however, we still do not know the exact impact of changing the price in the presence of many reputable requesters on the platform. Or, what happen when you post a link of a batch on a popular crowdsourcing forum etc.

In this paper we adopt a data-driven approach to analyze the behavior of the main actors in MTurk micro-task crowdsourcing: workers, requesters, HITs, and platform (MTurk); thanks to a collection of datasets that we gathered during the last 5 year.

The ultimate contribution that we propose is a predictive model to derive the expected performance of a published batch of HITs on MTurk at a specific moment in time.

\end{abstract}

% A category with the (minimum) three required fields
\category{H.4}{Information Systems Applications}{Miscellaneous}
%A category including the fourth, optional field follows...
% \category{D.2.8}{Software Engineering}{Metrics}[complexity measures, performance measures]

\terms{Design, Experimentation, Human Factors}

\keywords{Crowdsourcing, social networks, log analysis}

\input{sections/intro}
\input{sections/relwork}

\section{The Amazon Mechanical Turk Crowdsourcing Platform}

\section{The Evolution of MTurk}
2009-2014
\subsection{A Data-driven Analysis}
Datasets: tracker, to, 
\subsection{Why Did Certain Topics Became Popular?}
\subsection{Why Did Certain Countries Were Preferred?}
top keywords per country (over time)
\subsection{Why Did Certain Requesters Quit?}
% \subsection{Does reputation Improve Throughput?}

\section{Large-Scale HIT Type Analysis}



\section{Predicting the Platform Throughput}
\begin{itemize}

	\item ML tasks: classification and regression

	\item ML results: accuracy and error

	\item Best features

\end{itemize}

\section{Conclusions}

\end{document}
